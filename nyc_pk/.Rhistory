col_sums <- apply(my_mat,2, sum)
# sum of diagonal and inverse diagonal
diag_sum <- sum(diag(x = my_mat))
rev_diag_sum <- sum(lava::revdiag(my_mat))
# combine sums together in single vector for looping
sum_vector <- c(row_sums, col_sums, diag_sum, rev_diag_sum)
check_sum <- diag_sum # have diagonal sum serve as reference check
agree_TF <- TRUE
for (i in 1:length(sum_vector)) {
if(sum_vector[i] != check_sum){
agree_TF <- FALSE # return early with False if an element does not match the check sum
break
}
}
return(agree_TF)
}
test_matrix <- cbind(
c(2, 9, 4),
c(7, 5, 3),
c(6, 1, 8)
)
(is_magic(test_matrix))
is_magic <- function(mat){
# sum of rows and columns
row_sums <- apply(mat,1, sum)
col_sums <- apply(mat,2, sum)
# sum of diagonal and inverse diagonal
diag_sum <- sum(diag(x = mat))
rev_diag_sum <- sum(lava::revdiag(mat))
# combine sums together in single vector for looping
sum_vector <- c(row_sums, col_sums, diag_sum, rev_diag_sum)
check_sum <- diag_sum # have diagonal sum serve as reference check
agree_TF <- TRUE
for (i in 1:length(sum_vector)) {
if(sum_vector[i] != check_sum){
agree_TF <- FALSE # return early with False if an element does not match the check sum
break
}
}
return(agree_TF)
}
(is_magic(test_matrix))
(is_magic(my_mat))
install.packages('shiny')
library(shiny)
runApp('Jason/R/Mastering Shiny/Chapter 2/first_Shiny_app')
runApp('Jason/R/Mastering Shiny/Chapter 2/first_Shiny_app/app_2.R')
runApp('Jason/R/Mastering Shiny/Chapter 2/first_Shiny_app/app_3.R')
runApp('Jason/R/Mastering Shiny/Chapter 2/chapter2_Ex/app_Ch2Ex1.R')
runApp('Jason/R/Mastering Shiny/Chapter 2/chapter2_Ex/app_Ch2Ex1.R')
runApp('Jason/R/Mastering Shiny/Chapter 2/chapter2_Ex/app_Ch2Ex1.R')
rm(list = ls())
x <- c(1, 3, 2, 5)
x
x = c(1, 6, 2)
x
y = c(1, 4, 3)
length(x)
length(y)
x + y
ls()
rm(x, y)
ls
ls()
rm(list = ls())
?matrix
x <- matrix()
x <- matrix(
data = c(1, 2, 3, 4),
nrow = 2,
ncol = 2,
)
x
x <- matrix(c(1,2,3,4), 2, 2, byrow=TRUE)
X
x
sqrt(x)
x^2
x <- rnorm(50)
y <- x + rnorm(50, mean = 50, sd=.1)
cor(x, y)
set.seed(3)
rnorm(50)
set.seed(3)
y <- rnorm(100)
mean(y)
var(y)
sqrt(y)
sqrt(var(y))
sd(y)
library(ggplot2)
g <- ggplot() +
geom_point(mapping = aes(x = rnorm(100), y = rnorm(100)))
g
x <- rnorm(100)
y <- rnorm(100)
plot(x, y)
plot(x, y, xlab = "this is the x-axis", ylab="this is the y-axis", main="Plot of X vs Y")
g <- ggplot() +
geom_point(mapping = aes(x = rnorm(100), y = rnorm(100)))
g
pdf("Figure.pdf")
plot(x, y, col="green")
dev.off
x <-seq(1,10)
x
x <- 1:10
x
x <- seq(-pi, pi, length=50)
x
y <- x
f <- outer(x, y, function(x, y)cos(y)/(1+x^2))
contour(x, y, f)
contour(x, y, f, nlevels = 45, add = T)
contour(x, y, f, nlevels = 45, add = T)
contour(x, y, fa, nlevels=15)
fa <- (f-t(f)) / 2
contour(x, y, fa, nlevels=15)
contour(x, y, f)
contour(x, y, f, nlevels = 45, add = T)
fa <- (f-t(f)) / 2
contour(x, y, fa, nlevels=15)
image(x, y, fa)
persp(x, y, fa)
persp(x, y, fa, theta=30)
persp(x, y, fa, theta=30, phi=20)
persp(x, y, fa, theta=30, phi=70)
persp(x, y, fa, theta=30, phi=40)
library(ISLR)
fix(Auto)
head(Auto)
dim(Auto)
names(Auto)
plot(Auto$cylinders, Auto$mpg)
plot(cylinders, mpg)
cylinders <- as.factor(cylinders)
plot(x=cylinders, y=mpg)
plot(x=cylinders, y=mpg)
plot(x=Auto$cylinders, y=Auto$mpg)
cylinders <- as.factor(Auto$cylinders)
plot(x=cylinders, y=Auto$mpg)
plot(x=cylinders, y=Auto$mpg, col="red", varwidth=T, horizontal=T)
hist(mpg, col=2, breaks=15)
hist(Auto$mpg, col=2, breaks=15)
pairs(Auto)
pairs(~mpg + displacement + horsepower + weight + acceleration, Auto)
plot(horsepower, mpg)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, name)
attach(Auto)
plot(horsepower, mpg)
identity(horsepower, mpg, name)
attach(Auto)
# plot(horsepower, mpg)
identity(horsepower, mpg, name)
# plot(horsepower, mpg)
identity(horsepower)
# plot(horsepower, mpg)
identify(horsepower, mpg, name)
install.packages(c("ggplot2", "tidyverse", "ISLR"))
A = matrix(1:16, 4, 4)
A
A[2, 3]
A[c(1, 3), c(2, 4)]
a[1:3, 2:4]
A[1:3, 2:4]
install.packages(c("BH", "cli", "fansi", "farver", "hms", "knitr", "prettyunits", "rmarkdown", "SQUAREM", "stringi", "tinytex", "xfun"))
install.packages(c("rlang", "tidyselect"))
install.packages(c("dplyr", "rlang", "tidyselect", "yaml"))
library(tidyverse)
#1
g <- ggplot(data = cars, mapping = aes(x = speed, y = dist)) +
geom_point()
#2
g + ggtitle("Stopping Distance vs. Speed")
#2
g +
ggtitle("Stopping Distance vs. Speed") +
ylab("Stopping Distance (ft)") +
xlab("Speed (mpg)")
#2
g <- g +
ggtitle("Stopping Distance vs. Speed") +
ylab("Stopping Distance (ft)") +
xlab("Speed (mpg)")
g
#3
g + geom_point(color='red')
#3
g + geom_point(color='red', shape=17)
?geom_point
# question 2
as.tipple(faithful)
as.tibble(faithful)
as_tibble(faithful)
ifelse(test = eruption > 3.2, yes = "short", no = "long")
ifelse(test = faithful$eruption > 3.2, yes = "short", no = "long")
f <- faithful
f$length <- ifelse(test = faithful$eruption > 3.2, yes = "short", no = "long")
f
ggplot(data = f, mapping = aes(x = f$length, y = f$waiting)) +
geom_boxplot()
ggplot(data = f, mapping = aes(x = f$length, y = f$waiting)) +
geom_boxplot() +
geom_density()
ggplot(data = f, mapping = aes(x = f$length, y = f$waiting)) +
geom_boxplot() +
geom_density(y = f$waiting)
# 3
Knicks.rda
load(url('https://s3.amazonaws.com/graderdata/Knicks.rda'))
# 3
load(url('https://s3.amazonaws.com/graderdata/Knicks.rda'))
as.tibble(data)
data %>%
group_by(., season) %>%
mutate(., win_TF = win == "W") %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF))
data %>%
group_by(., season) %>%
mutate(., win_TF = win == "W") %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games)
data %>%
group_by(., season) %>%
mutate(., win_TF = win == "W") %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) +
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col()
data %>%
group_by(., season) %>%
mutate(., win_TF = win == "W") %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) %>%
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col()
data %>%
group_by(., season) %>%
mutate(., win_TF = win == "W") %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) %>%
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col() +
ggtitle("New York Knicks Win % by Season")
# Part II
data %>%
group_by(., season, visiting) %>%
mutate(., win_TF = win == "W", home_away = ifelse(test = visiting == 1, yes = "Away", no = "Home")) %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games)
# Part II
data %>%
mutate(., win_TF = win == "W", home_away = ifelse(test = visiting == 1, yes = "Away", no = "Home")) %>%
group_by(., season, home_away) %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games)
# Part II
data %>%
mutate(., win_TF = win == "W", home_away = ifelse(test = visiting == 1, yes = "Away", no = "Home")) %>%
group_by(., season, home_away) %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) %>%
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col() +
ggtitle("New York Knicks Win % by Season")
# Part II
data %>%
mutate(., win_TF = win == "W", home_away = ifelse(test = visiting == 1, yes = "Away", no = "Home")) %>%
group_by(., season, home_away) %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) %>%
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col(aes(fill = home_away)) +
ggtitle("New York Knicks Win % by Season")
# Part II
data %>%
mutate(., win_TF = win == "W", home_away = ifelse(test = visiting == 1, yes = "Away", no = "Home")) %>%
group_by(., season, home_away) %>%
summarise(., tot_games = n(), tot_wins = sum(win_TF)) %>%
mutate(., win_ratio = tot_wins / tot_games) %>%
ggplot(data = ., mapping = aes(x = season, y = win_ratio)) +
geom_col(aes(fill = home_away), position = "dodge") +
ggtitle("New York Knicks Win % by Season")
# Part III
data %>%
ggplot(data = ., mapping(aes(x = points))) +
geom_histogram()
# Part III
data %>%
ggplot(data = ., mapping = (aes(x = points))) +
geom_histogram()
# Part III
data %>%
ggplot(data = ., mapping = (aes(x = points))) +
geom_histogram() +
facet_wrap(., rows = vars(season))
# Part III
data %>%
ggplot(data = ., mapping = (aes(x = points))) +
geom_histogram() +
facet_grid(., rows = vars(season))
# Part III
data %>%
ggplot(data = ., mapping = (aes(x = points))) +
geom_histogram() +
facet_grid(rows = vars(season))
install.packages(c("dplyr", "jsonlite", "mapproj", "rlang", "tidyselect"))
library(leaflet)
library(maps)
Andrew <- leaflet(Andrew)
library(googleVis)
library(tidyverse)
leaflet(Andrew) %>% as_tibble(.)
leaflet(Andrew)
install.packages(c("dplyr", "DT", "jsonlite", "mapproj", "mime", "rlang", "tidyselect"))
library(shiny)
library(shinydashboard)
library(janitor)
library(leaflet)
library(leaflet.providers)
library(tmap)
library(tmaptools)
library(maps)
library(tidyverse)
options(scipen = 999)
# collect file paths
nyc_pop_by_nta_fp <- "./data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv"
nyc_pk_loc_fp <- "./data/Universal_Pre-K__UPK__School_Locations.csv"
# location information for pre-k schools in NYC
nyc_pk <- read_csv(file = nyc_pk_loc_fp)
nyc_pk <- nyc_pk %>% rename(., lat = Latitude, lng = Longitude)
# geo information for nyc's nta grid (nta = neighborhood tabular area)
nyc_nta_sf <- geojson_sf(geojson = './data/nyc_nta.geojson')
# population import
nyc_pop <- read_csv(file = nyc_pop_by_nta_fp)
nyc_pop
nyc_pop <- nyc_pop %>% filter(., Year == 2010) # only bring in 2010 census information that is in the file
# name clean
nyc_pop <- clean_names(dat = nyc_pop)
nyc_nta_sf <- clean_names(dat = nyc_nta_sf)
nyc_pk <- clean_names(data = nyc_pk)
# combine map and population information
map_and_pop <- right_join(x = nyc_pop, y = nyc_nta_sf, by = 'nta_code')
# combine pk school information together with map_and_pop
map_and_pk_and_pop <- inner_join(x = pk_by_nta, y = map_and_pop_dos, by = c("nta" = "nta_name.x")) %>%
mutate(., seats_per_1000 = seats_per_nta / (population / 1000)) %>%
st_as_sf(x = ., sf_column_name = "geometry") # has to be converted back to a spatial form data type
setwd("~/Jason/NYC Data Science Academy/projects/shiny/nyc_pk_schools/nyc_pk")
library(shiny)
library(shinydashboard)
library(janitor)
library(leaflet)
library(leaflet.providers)
library(tmap)
library(tmaptools)
library(maps)
library(tidyverse)
options(scipen = 999)
# collect file paths
nyc_pop_by_nta_fp <- "./data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv"
nyc_pk_loc_fp <- "./data/Universal_Pre-K__UPK__School_Locations.csv"
# location information for pre-k schools in NYC
nyc_pk <- read_csv(file = nyc_pk_loc_fp)
nyc_pk <- nyc_pk %>% rename(., lat = Latitude, lng = Longitude)
# geo information for nyc's nta grid (nta = neighborhood tabular area)
nyc_nta_sf <- geojson_sf(geojson = './data/nyc_nta.geojson')
# population import
nyc_pop <- read_csv(file = nyc_pop_by_nta_fp)
nyc_pop
nyc_pop <- nyc_pop %>% filter(., Year == 2010) # only bring in 2010 census information that is in the file
# name clean
nyc_pop <- clean_names(dat = nyc_pop)
nyc_nta_sf <- clean_names(dat = nyc_nta_sf)
nyc_pk <- clean_names(data = nyc_pk)
# combine map and population information
map_and_pop <- right_join(x = nyc_pop, y = nyc_nta_sf, by = 'nta_code')
# combine pk school information together with map_and_pop
map_and_pk_and_pop <- inner_join(x = pk_by_nta, y = map_and_pop_dos, by = c("nta" = "nta_name.x")) %>%
mutate(., seats_per_1000 = seats_per_nta / (population / 1000)) %>%
st_as_sf(x = ., sf_column_name = "geometry") # has to be converted back to a spatial form data type
# aggregate pk school information at the nta level
pk_by_nta <- nyc_pk %>%
group_by(., borough, nta) %>%
summarise(., schl_per_nta = n(), seats_per_nta = sum(seats)) %>%
ungroup()
# aggregate pk school information at the nta level
pk_by_nta <- nyc_pk %>%
clean_names(.) %>%
group_by(., borough, nta) %>%
summarise(., schl_per_nta = n(), seats_per_nta = sum(seats)) %>%
ungroup()
library(shiny)
library(shinydashboard)
library(janitor)
library(leaflet)
library(leaflet.providers)
library(tmap)
library(tmaptools)
library(maps)
library(tidyverse)
options(scipen = 999)
# collect file paths
nyc_pop_by_nta_fp <- "./data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv"
nyc_pk_loc_fp <- "./data/Universal_Pre-K__UPK__School_Locations.csv"
# location information for pre-k schools in NYC
nyc_pk <- read_csv(file = nyc_pk_loc_fp)
nyc_pk <- nyc_pk %>% rename(., lat = Latitude, lng = Longitude)
# aggregate pk school information at the nta level
pk_by_nta <- nyc_pk %>%
clean_names(.) %>%
group_by(., borough, nta) %>%
summarise(., schl_per_nta = n(), seats_per_nta = sum(seats)) %>%
ungroup()
# geo information for nyc's nta grid (nta = neighborhood tabular area)
nyc_nta_sf <- geojson_sf(geojson = './data/nyc_nta.geojson')
# population import
nyc_pop <- read_csv(file = nyc_pop_by_nta_fp)
nyc_pop
nyc_pop <- nyc_pop %>% filter(., Year == 2010) # only bring in 2010 census information that is in the file
# name clean
nyc_pop <- clean_names(dat = nyc_pop)
nyc_nta_sf <- clean_names(dat = nyc_nta_sf)
# combine map and population information
map_and_pop <- right_join(x = nyc_pop, y = nyc_nta_sf, by = 'nta_code')
# combine pk school information together with map_and_pop
map_and_pk_and_pop <- inner_join(x = pk_by_nta, y = map_and_pop_dos, by = c("nta" = "nta_name.x")) %>%
mutate(., seats_per_1000 = seats_per_nta / (population / 1000)) %>%
st_as_sf(x = ., sf_column_name = "geometry") # has to be converted back to a spatial form data type
library(shiny)
library(shinydashboard)
library(geojson)
library(janitor)
library(leaflet)
library(leaflet.providers)
library(tmap)
library(tmaptools)
library(maps)
library(tidyverse)
options(scipen = 999)
# collect file paths
nyc_pop_by_nta_fp <- "./data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv"
nyc_pk_loc_fp <- "./data/Universal_Pre-K__UPK__School_Locations.csv"
# location information for pre-k schools in NYC
nyc_pk <- read_csv(file = nyc_pk_loc_fp)
nyc_pk <- nyc_pk %>% rename(., lat = Latitude, lng = Longitude)
# aggregate pk school information at the nta level
pk_by_nta <- nyc_pk %>%
clean_names(.) %>%
group_by(., borough, nta) %>%
summarise(., schl_per_nta = n(), seats_per_nta = sum(seats)) %>%
ungroup()
# geo information for nyc's nta grid (nta = neighborhood tabular area)
nyc_nta_sf <- geojson_sf(geojson = './data/nyc_nta.geojson')
# population import
nyc_pop <- read_csv(file = nyc_pop_by_nta_fp)
nyc_pop
nyc_pop <- nyc_pop %>% filter(., Year == 2010) # only bring in 2010 census information that is in the file
# name clean
nyc_pop <- clean_names(dat = nyc_pop)
nyc_nta_sf <- clean_names(dat = nyc_nta_sf)
# combine map and population information
map_and_pop <- right_join(x = nyc_pop, y = nyc_nta_sf, by = 'nta_code')
# combine pk school information together with map_and_pop
map_and_pk_and_pop <- inner_join(x = pk_by_nta, y = map_and_pop, by = c("nta" = "nta_name.x")) %>%
mutate(., seats_per_1000 = seats_per_nta / (population / 1000)) %>%
st_as_sf(x = ., sf_column_name = "geometry") # has to be converted back to a spatial form data type
runApp()
runApp()
library(shiny)
library(shinydashboard)
library(geojsonsf)
library(sf)
library(janitor)
library(leaflet)
library(leaflet.providers)
library(tmap)
library(tmaptools)
library(maps)
library(tidyverse)
options(scipen = 999)
# collect file paths
nyc_pop_by_nta_fp <- "./data/New_York_City_Population_By_Neighborhood_Tabulation_Areas.csv"
nyc_pk_loc_fp <- "./data/Universal_Pre-K__UPK__School_Locations.csv"
# location information for pre-k schools in NYC
nyc_pk <- read_csv(file = nyc_pk_loc_fp)
nyc_pk <- nyc_pk %>% rename(., lat = Latitude, lng = Longitude)
# aggregate pk school information at the nta level
pk_by_nta <- nyc_pk %>%
clean_names(.) %>%
group_by(., borough, nta) %>%
summarise(., schl_per_nta = n(), seats_per_nta = sum(seats)) %>%
ungroup()
# geo information for nyc's nta grid (nta = neighborhood tabular area)
nyc_nta_sf <- geojson_sf(geojson = './data/nyc_nta.geojson')
# population import
nyc_pop <- read_csv(file = nyc_pop_by_nta_fp)
nyc_pop
nyc_pop <- nyc_pop %>% filter(., Year == 2010) # only bring in 2010 census information that is in the file
# name clean
nyc_pop <- clean_names(dat = nyc_pop)
nyc_nta_sf <- clean_names(dat = nyc_nta_sf)
# combine map and population information
map_and_pop <- right_join(x = nyc_pop, y = nyc_nta_sf, by = 'nta_code')
# combine pk school information together with map_and_pop
map_and_pk_and_pop <- inner_join(x = pk_by_nta, y = map_and_pop, by = c("nta" = "nta_name.x")) %>%
mutate(., seats_per_1000 = seats_per_nta / (population / 1000)) %>%
st_as_sf(x = ., sf_column_name = "geometry") # has to be converted back to a spatial form data type
runApp()
runApp()
runApp()
